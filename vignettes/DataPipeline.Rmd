---
title: "Data Pipeline"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Data Pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(gsm)
library(gt)
library(dplyr)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

The `{gsm}` package provides a standardized workflow that leverages Key Risk Indicators (KRIs) and thresholds to conduct study-level Risk Based Quality Management (RBQM) for clinical trials. This vignette provides an overview of the `{gsm}` data model. First, we provide a summary of the standardized data pipeline used to calculate KRIs and evaluate thresholds to set site-level flags. We also discuss workflows and reports that allow users to run multiple KRIs concurrently on a study and/or create custom data workflows.

As an overview, clinical and operational data are analyzed using the `{gsm}` R package, which generate standardized outputs and reports suitable for use in various RBQM activities. The Appendices of this document provide detailed data input and output specifications for `{gsm}`.

# KRI Data Pipeline

In the context of clinical research, a KRI is a measure of risk associated with the conduct of a clinical trial. Examples of KRIs include the rate of adverse events or amount of missing data at a site or across sites. Defining and deploying KRIs during study start-up allows sponsors to continually monitor risks to the integrity of the trial and take corrective actions accordingly.

The default KRI data pipeline begins with one or more clinical datasets related to the KRI. An optional participant-level subset is then applied to each dataset before aggregating by participant to quantify the KRI at the participant level. This aggregated dataset is then further summarized by site to obtain site-level metrics.

## Generating Input Data

Generating input data is outside the scope of the assessment pipeline. The specifications for input data (i.e., `dfInput`) are designed to be flexible enough so that this data frame can be generated from multiple clinical data standards (e.g., Raw, rawplus, or CDISC-compliant ADaM). In order to generate input data, the user uses the data frames outputted by the `mappings.yaml` file along with the `Input_Rate()` function to generate the `dfInput` needed for a particular KRI.


This `mapping.yaml` file is provided for convenience, but may not work for all clinical studies. When no relevant data.frame is produced with the `mapping.yaml`, the user can use the `RunQuery()` function to write a SQL query that produces the properly mapped and filtered dataframe. Details on this can be found in the [Cookbook Vignette](https://github.com/Gilead-BioStats/gsm/wiki/Cookbook-Vignette).

## Assessment Data Pipeline

![](data-analysis.PNG){width="100%"}

The image above provides an overview of the default KRI assessment pipeline. The pipeline is a standardized five-step process for assessing data issues by going from participant-level input data to a standardized site-level summary of model results. The functions used in each step of the data pipeline along with the input and output datasets are described in more detail below.

1.  `dfInput`: Input data; Cross-domain participant-level input data with all needed data for KRI derivation. Created by the `Input_Rate()` function as needed.
2.  `dfTransformed`: Transformed data; Site-level transformed data including KRI calculation. Created by `Transform()` functions.
3.  `dfAnalyzed`: Analyzed data; Site-level analysis results data. Created by `Analyze()` functions.
4.  `dfFlagged`: Flagged data; Site-level analysis results with flags added to indicate potential statistical outliers. Created by passing numeric thresholds to a `Flag()` function.
5.  `dfSummary`: Summary data; Standardized subset of the flagged data. This summary data has the same structure for all assessments and always includes both KRI and Flag values so that a user can easily look at trends for any given site across multiple assessments. Created using the `Summarize()` function.

Each KRI has a `.yaml` file that sequentially executes all of the supporting functions and returns a list of datasets and visualizations per the specifications of the .yaml file. In the default `yaml` files included in the `inst/workflow` directory of this package, the 5 standard datasets that are always returned are `dfTransformed`, `dfAnalyzed`, `dfFlagged`, `dfBounds`, and `dfSummary`. A step-by-step example of the data assessment workflow can be found in the [Data Analysis Vignette](https://gilead-biostats.github.io/gsm/articles/DataAnalysis.html).

Note that each step in this data pipeline can be customized based on the requirements for a specific KRI. The graphic below shows four such workflows.

![](data-analysis-combined.PNG){width="100%"}

# Custom Pipelines

## QTL and Country Analysis

The default KRI data pipeline runs site-level analyses on sourced clinical data. `{gsm}` also has the capability to run overall study-level analyses using Quality Tolerance Limits, or QTLs. For example, a user can evaluate the protocol deviation rate at a study-level. Analyses can also be categorized by country identifiers if desired. A user can also run custom pipelines (e.g. stratified analysis) as well (see [Appendix 3](#Appendix-3-Workflow-ID-Specs) for workflow nomenclature and examples).

## Running Multiple Assessments

Running multiple assessments simultaneously for a single study is a common use case of `{gsm}` and the package provides workflow and reporting functions to streamline this process.

TODO: update this to discuss use of yaml and MakeWorkflowList, RunWorkflow and RunStep

`RunWorkflow()` attempts to run one or more assessment workflows using shared data and metadata. The metadata used for this study-level assessment is described in detail in [Appendix 1](#Appendix-1-Metadata-Technical-Specifications). The `RunWorkflow()` function returns a list of assessments containing status information and results that is used as input for the reporting functions described below.

talk about `VisualizeMetric()` here

`Report_KRI()` creates a detailed report showing both charts and listings summarizing each KRI that was run for the study, along with a study-level table (via `Study_Table()`) and a summary of the workflow run to generate each KRI (via `Study_AssessmentReport()`) .

To see a sample report, run:

```{r, eval = FALSE}
# Prepare Workflows
wf_mapping <- MakeWorkflowList(strNames="mapping")[[1]]
wf_metrics <- MakeWorkflowList(strNames=paste0("kri",sprintf("%04d", 1:2)))
dfMetrics <- wf_metrics %>% map_df(~.x$meta)

# Import Site+Study Metadata
dfStudy<-clindata::ctms_study %>% rename(StudyID = protocol_number)
dfSite<- clindata::ctms_site %>% rename(SiteID = site_num)

# Pull Raw Data - this will overwrite the previous data pull
lRaw <- gsm::UseClindata(
  list(
    "dfSUBJ" = "clindata::rawplus_dm",
    "dfAE" = "clindata::rawplus_ae",
    "dfPD" = "clindata::ctms_protdev",
    "dfLB" = "clindata::rawplus_lb",
    "dfSTUDCOMP" = "clindata::rawplus_studcomp",
    "dfSDRGCOMP" = "clindata::rawplus_sdrgcomp",
    "dfDATACHG" = "clindata::edc_data_points",
    "dfDATAENT" = "clindata::edc_data_pages",
    "dfQUERY" = "clindata::edc_queries",
    "dfENROLL" = "clindata::rawplus_enroll"
  )
)

# Create Mapped Data
lMapped <- RunWorkflow(lWorkflow = wf_mapping, lData = lRaw)$lData

# Run Metrics
lResults <-wf_metrics %>% map(~RunWorkflow(lWorkflow=.x, lData=lMapped))

dfBounds <- lResults %>% 
  imap_dfr(~.x$lData$dfBounds %>% mutate(MetricID = .y)) %>%
  mutate(StudyID = "ABC-123") %>%
  mutate(SnapshotDate = Sys.Date())

dfSummary <- lResults %>% 
  imap_dfr(~.x$lData$dfSummary %>% mutate(MetricID = .y)) %>%
  mutate(StudyID = "ABC-123") %>%
  mutate(SnapshotDate = Sys.Date())

lCharts <- unique(dfSummary$MetricID) %>% map(~Visualize_Metric(
  dfSummary = dfSummary, 
  dfBounds = dfBounds, 
  dfSite = dfSite,
  dfMetrics = dfMetrics, 
  strMetricID = .x
)
) %>% setNames(unique(dfSummary$MetricID)) 

# Run reports 
strOutpath <- "gsm_site_report.html"
Report_KRI( lCharts = lCharts, 
            dfSummary = dfSummary,  
            dfSite = dfSite, 
            dfStudy = dfStudy, 
            dfMetrics = dfMetrics,
            strOutpath = strOutpath )
```

Additional examples are provided in the [Cookbook Vignette](https://gilead-biostats.github.io/gsm/articles/Cookbook.html).

# Appendix 1 - Data Model

# Overview 
![](data-model.PNG){width="100%"}


# Analytics data model

The KRI analytics pipeline is a standardized process for **Analyzing** data issues by going from participant-level `input` data to a standardized site-level `summary` of model results. The data sets used in each step of the data pipeline are described in detail below.

1. `input` data - Cross-domain participant-level input data with all needed data for KRI derivation.
2. `transformed` data - Site-level transformed data including KRI calculation. Created by `Transform` functions. 
3. `analyzed` data - Site-level analysis result data. Created by `Analyze` functions. 
4. `flagged` data - Site-level analysis results with flags added. Created by passing numeric `thresholds` to a `Flag` function.
5. `summary` data - Standardized subset the flagged data. This summary data has the same structure for all assessments and always includes both `KRI` and `Flag` values so that we can easily look at trends for any given site across multiple assessments. Created using a `Summarize` Function. 

During this process, we also create `bounded` data that creates upper- and lower- bounds across the full range of exposure values. This is created in the analytics pipeline, but primarily used in the reporting pipeline.

## Analytics Data Tables
  
### `dfInput`
  - Function(s) used to create table: 
    - `Input_Rate()`
  - Inputs: 
    - `dfSubjects`
    - `dfNumerator`
    - `dfDenominator`
  - Usage: The base data.frame for all Analytics workflows. Feeds into the `Transform_XX` functions.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | 
  |----------|--------------|--------------------------------------|----------|--|
  | dfInput  | SubjectID    | The subject ID                       | Character| |
  | dfInput  | GroupID      | The group ID for the metric          | Character| | |
  | dfInput  | GroupLevel   | The group type for the metric (e.g. "Site")    | Character| | 
  | dfInput  | Numerator    | The calculated numerator value       | Numeric  | |
  | dfInput  | Denominator  | The calculated denominator value     | Numeric | |
  | dfInput  | Metric       | The calculated rate/metric value     | Numeric  | |


### `dfTransformed`
  - Function(s) used to create table:
    - `Transform_Rate()`
    - `Transform_Count()`
  - Inputs: `dfInput`
  - Usage: Convert from input data format to needed format to derive KRI for an Assessment via the `Analyze_XX` functions.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | 
  |----------|--------------|--------------------------------------|----------|--|
  | dfTransformed | GroupID      | The group ID for the metric          | Character| | |
  | dfTransformed | GroupLevel   | The group type for the metric (e.g. "Site")    | Character| | 
  | dfTransformed | Numerator    | The calculated numerator value       | Numeric  | |
  | dfTransformed | Denominator  | The calculated denominator value     | Numeric | |
  | dfTransformed | Metric       | The calculated rate/metric value     | Numeric  | |

###  `dfAnalyzed`
  - Function(s) used to create table:
    - `Analyze_Fisher()`
    - `Analyze_Identity()`
    - `Analyze_NormalApprox()`
    - `Analyze_Poisson()`
    - `Analyze_QTL()`
  - Inputs: `dfTransformed`
  - Usage: Prepare the data for `Flag_XX` by performing the specified test on the metric provided.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | 
  |----------|--------------|--------------------------------------|----------|--|
  | dfAnalyzed | GroupID      | The group ID for the metric          | Character| | |
  | dfAnalyzed | GroupLevel   | The group type for the metric (e.g. "Site")    | Character| | 
  | dfAnalyzed | Numerator    | The calculated numerator value       | Numeric  | |
  | dfAnalyzed | Denominator  | The calculated denominator value     | Numeric | |
  | dfAnalyzed | Metric       | The calculated rate/metric value     | Numeric  | |
  | dfAnalyzed | Score        | The Statistical Score      | Numeric  | |
  | dfAnalyzed | Overall Metric |       | Numeric  |* |
  | dfAnalyzed | Factor |      | Numeric  |* |
  | dfAnalyzed | Predicted Count |      | Numeric  |* |


### `dfBounds`
  - Function(s) used to create table:
    - `Analyze_NormalApprox_PredictBounds()`
    - `Analyze_Poisson_PredictBounds()`
  - Inputs: `dfTransformed`
  - Usage: Calculates predicted percentages/rates and upper- and lower-bounds across the full range of sample sizes/total exposure values for reporting.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | 
  |----------|--------------|--------------------------------------|----------|--|
  | dfBounds | Threshold    | The number of standard deviations that the upper and lower bounds are based on   | Numeric| | |
  | dfBounds | Denominator  | The calculated denominator value     | Numeric | |
  | dfBounds | LogDenominator  | The calculated log denominator value     | Numeric | |
  | dfBounds | Numerator    | The calculated numerator value       | Numeric  | |
  | dfBounds | Metric       | The calculated rate/metric value     | Numeric  | |
  | dfBounds | MetricID     | The Metric ID                        | Character| * |
  | dfBounds | StudyID      | The Study ID                         | Character| * |
  | dfBounds | SnapshotDate | The Date of the snapshot             | Date     | * |
  
### `dfFlagged`
  - Function(s) used to create table:
    - `Flag_Fisher()`
    - `Flag_Identity()`
    - `Flag_NormalApprox()`
    - `Flag_Poisson()`
    - `Flag_QTL()`
  - Inputs: `dfAnalyzed`
  - Usage: Flag a group-level metric to be summarized via `Summarize()` and used for reporting.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | 
  |----------|--------------|--------------------------------------|----------|--|
  | dfFlagged | GroupID      | The group ID for the metric          | Character| | |
  | dfFlagged | GroupLevel   | The group type for the metric (e.g. "Site")    | Character| | 
  | dfFlagged | Numerator    | The calculated numerator value       | Numeric  | |
  | dfFlagged | Denominator  | The calculated denominator value     | Numeric | |
  | dfFlagged | Metric       | The calculated rate/metric value     | Numeric  | |
  | dfFlagged | Score        | The Statistical Score     | Numeric  | |  
  | dfFlagged | Flag        | The ordinal Flag to be applied     | Numeric  | |  
  | dfFlagged | Overall Metric |       | Numeric  |* |
  | dfFlagged | Factor |      | Numeric  |* |
  | dfFlagged | Predicted Count |      | Numeric  |* |

###  `dfSummary`
  - Function(s) used to create table:
    - `Summarize()`
  - Inputs: `dfFlagged`
  - Usage: Summarize KRI at the group level for reporting.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | 
  |----------|--------------|--------------------------------------|----------|--|
  | dfSummary      | GroupID      | The group ID for the metric          | Character| | |
  | dfSummary      | GroupLevel   | The group type for the metric (e.g. "Site")    | Character| | 
  | dfSummary      | Numerator    | The calculated numerator value       | Numeric  | |
  | dfSummary      | Denominator  | The calculated denominator value     | Numeric | |
  | dfSummary      | Metric       | The calculated rate/metric value     | Numeric  | |
  | dfSummary      | MetricID     | The Metric ID                        | Character| * |
  | dfSummary      | StudyID      | The Study ID                         | Character| * |
  | dfSummary      | SnapshotDate | The Date of the snapshot             | Date     | * |

# Overview of Reporting data model
  
## Reporting Data Tables
  
###  `dfSummary`
  - Function(s) used to create table:
    - `Summarize()`
  - Inputs: `dfFlagged`
  - Usage: Summarize KRI at the group level for reporting.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  |  rbm-viz Column Name |
  |----------|--------------|--------------------------------------|----------|--|-----------|
  | dfSummary      | GroupID      | The group ID for the metric          | Character| | groupid |
  | dfSummary      | GroupLevel   | The group type for the metric (e.g. "Site")    | Character| | - |
  | dfSummary      | Numerator    | The calculated numerator value       | Numeric  | | numerator |
  | dfSummary      | Denominator  | The calculated denominator value     | Numeric | | denominator |
  | dfSummary      | Metric       | The calculated rate/metric value     | Numeric  | | metric |
  | dfSummary      | Score        | The calculated metric score          | Numeric  | | score |
  | dfSummary      | Flag         | The calculated flag                  | Numeric  | | flag |
  | dfSummary      | MetricID     | The Metric ID                        | Character| * | workflowid |
  | dfSummary      | StudyID      | The Study ID                         | Character| * | studyid |
  | dfSummary      | SnapshotDate | The Date of the snapshot             | Date     | * | snapshot_date |

### `dfBounds`
  - Function(s) used to create table:
    - `Analyze_NormalApprox_PredictBounds()`
    - `Analyze_Poisson_PredictBounds()`
  - Inputs: `dfTransformed`
  - Usage: Calculates predicted percentages/rates and upper- and lower-bounds across the full range of sample sizes/total exposure values for reporting.
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  |   rbm-viz Column Name |
  |----------|--------------|--------------------------------------|----------|--|----------|
  | dfBounds | Threshold    | The number of standard deviations that the upper and lower bounds are based on   | Numeric| | threshold |
  | dfBounds | Denominator  | The calculated denominator value     | Numeric | | denominator |
  | dfBounds | LogDenominator  | The calculated log denominator value     | Numeric | | log_denominator |
  | dfBounds | Numerator    | The calculated numerator value       | Numeric  | | numerator |
  | dfBounds | Metric       | The calculated rate/metric value     | Numeric  | | - |
  | dfBounds | MetricID     | The Metric ID                        | Character| * | workflowid |
  | dfBounds | StudyID      | The Study ID                         | Character| * | studyid |
  | dfBounds | SnapshotDate | The Date of the snapshot             | Date     | * | snapshot_date |

###  `dfGroups`
  - Workflow used to create table: `GroupMeta`
  - Inputs: CTMS site, study and country data
  - Usage: Group-level metadata dictionary.
  - Structure: Long data frame, with certain `Param` required for given `GroupLevel`


| Table       | Column                | Description                       |Type      | Optional  |  
|-------------|-----------------------|-----------------------------------|----------|-----------|
| dfGroups | ProtocolID               | Protocol ID                       | Character | |
| dfGroups | SnapshotDate             | Snapshot Date                     | Character | |
| dfGroups | GroupID                  | Unique Group ID                   | Character| | 
| dfGroups | GroupLevel               | Group Level (e.g. Site, Country)  | Character| |
| dfGroups | Param                    | Parameter Name (e.g. "Status")  | Character| | 
| dfGroups | Value                    | Parameter Value (e.g. "Active")        | Character| | 

Expected `Param` by `GroupLevel` for use in gsm reporting. Fine to add other Param values as needed. 

| GroupLevel  | Param                | Description                       |Value Type      |
|-------------|----------------------|-----------------------------------|----------|
| Study       | Status               | Study Status                      | Character| 
| Study       | Title       | Protocol Title       | Numeric | 
| Study       | ParticipantCount       | # of Enrolled Participants        | Numeric | 
| Study       | SiteCount              | # of Activated Sites                 | Numeric| 
| Study       | ParticipantsPlanned        | # of Planned Participants        | Numeric| 
| Study       | SitesPlanned               | # of Planned Sites        | Numeric| 
| Site       | ParticipantCount       | # of Enrolled Participants        | Numeric | 
| Site       | Status       | Site Status       | Character | 
| Site       | InvestigatorFirstName       | Investigator First name        | Character | 
| Site       | InvestigatorLastName       | Investigator Last name        | Character | 
| Site       | City        | City       | Character| 
| Site       | State       | State      | Character | 
| Site       | Country       | Country       | Character | 
| Country       | EnrolledParticipants       | # of Enrolled Participants        | Numeric | 


###  `dfMetrics`
  - Function used to create table:
  - Inputs:
  - Usage:
  - Structure:

  | Table    | Column Name  | Description                          | Type     | Optional  | rbm-viz Column Name |
  |----------|--------------|--------------------------------------|----------|--| -------------- |
  | dfMetrics| File         | The yaml file for workflow          | Character| | file          | 
  | dfMetrics| MetricID     | ID for the Metric   | Character| | workflowid |
  | dfMetrics| Group        | The group type for the metric (e.g. "Site")      | Character| | group |
  | dfMetrics| Abbreviation | Abbreviation for the metric   | Character| | abbreviations |
  | dfMetrics| Metric       | Name of the metric    | Character| | metric |
  | dfMetrics| Numerator    | Data source for the Numerator          | Character| |numerator      |
  | dfMetrics| Denominator  | Data source for the Denominator | Character| | denominator   |
  | dfMetrics| Model        | Model used to calculate metric     | Character| | model         |
  | dfMetrics| Score        | Type of Score reported      | Character| | score         |
  | dfMetrics| strThreshold   | Thresholds to be used for bounds and flags     | Character| | vthreshold    |


# Previous Versions

###  `dfSite`
  - Function used to create table:
  - Inputs:
  - Usage:
  - Structure:

| Table       | Column                | Description                       |Type      | Optional  |   rbm-viz Column Name |
|-------------|-----------------------|-----------------------------------|----------|-----------|-----------|
| dfSite | protocol_row_id       | Protocol row ID                   | Character | |protocol_row_id  | 
| dfSite | SiteID                | Unique Site ID                    | Character| | site_id  |
| dfSite | site_row_id           | Site row ID                       | Character| | site_row_id  |
| dfSite | protocol              | Protocol ID                       | Character| | protocol  |
| dfSite | pi_number             | Principal Investigator Number     | Character| | pi_number |
| dfSite | pi_last_name          | Principal Investigator Last Name  | Character| | pi_last_name|
| dfSite | pi_first_name         | Principal Investigator First Name | Character| | pi_first_name |
| dfSite | site_status           | Site Status                       | Character | | site_status |
| dfSite | is_satellite          | Is site a satellite location      | Character| | is_satellite  |
| dfSite | account               |                                   | Character| | account   |
| dfSite | site_active_dt        | Date that Site became active      | Character| | site_active_dt |
| dfSite | city                  | Site City                         | Character| | city |
| dfSite | state                 | Site State                        | Character| | state  |
| dfSite | country               | Site Country                      | Character| | country |

###  `dfStudy`
  - Function used to create table:
  - Inputs:
  - Usage:
  - Structure:

| Table       | Column                | Description                       |Type      | Optional  |
|-------------|-----------------------|-----------------------------------|----------|-----------|
| dfStudy| protocol_row_id       | Protocol row ID                   | Character | |
| dfStudy| StudyID               | Unique Study ID                   | Character| |
| dfStudy| protocol_title        | Protocol Title                    | Character| |
| dfStudy| nickname              | Protocol Nickname  | Character| |
| dfStudy| protocol_type         | Protocol Type                     | Character| |
| dfStudy| phase                 | Study phase  | Character| |
| dfStudy| num_plan_site         | Number of planned sites in the study | Character| |
| dfStudy| num_site_actl         | Number of active sites in the study | Character | |
| dfStudy| est_fpfv              | Estimated first patient first visit      | Date   | |
| dfStudy| act_fpfv              | Actual first patient first visit      | Date   | |
| dfStudy| est_lplv              | Estimated last patient last visit     | Date   | |
| dfStudy| act_lplv              | Actual last patient last visit       | Date   | |
| dfStudy| est_lpfv              | Estimated last patient first visit     | Date   | |
| dfStudy| act_lpfv              | Actual last patient first visit       | Date   | |
| dfStudy| status                | Study Status                       | Character| |
| dfStudy| num_plan_subj         | Number of planned subjects in study      | Numeric | |
| dfStudy| num_enrolled_subj_m   | Number of enrolled subjects in study | Numeric | |
| dfStudy| protocol_indication   | Protocol Indication                        | Character| |
| dfStudy| product               | Product                      | Character| |
| dfStudy| therapeutic_area      | Therapeutic Area                 | Character| |
| dfStudy| protocol_product_number| Protocol Product Number                      | Numeric | |
| dfStudy| x_rbm_flg             | Is RBM Flagged                      | Character| |



## Appendix 2 - Workflow Specifications

Assessment workflow metadata objects are passed to the `lWorkflow` parameter in `RunWorkflow()` to define functions and parameters across multiple studies.

The `lWorkflow` object is a named list of metadata and steps defining how each assessment should be run. By default, `MakeWorkflowList()` imports YAML specifications from `inst/workflow`. Each item in `lWorkflow` expects the following parameters in the `steps` section:

-   `workflow`: Array defining one or more functions to be executed as part of the workflow for a given assessment
    -   `workflow[]$name`: name of the `{gsm}` function.
    -   `workflow[]$inputs`: specifies the required input data
    -   `workflow[]$output`: specifies the output data from the workflow step, which can be used as an input in the next step in the workflow
    -   `workflow[]$params`: specifies parameters to be passed to the function
    
Additionally, there is `meta` information passed through that varies depending on the type of workflow. For 

For example, the default workflow for the AE assessment (`inst/workflow/kri0001.yaml`) is shown below:

```{yaml, eval = FALSE}
meta:
  MetricID: kri0001
  File: kri0001.yaml
  Group: site
  Abbreviation: AE
  Metric: Adverse Event Rate
  Numerator: Adverse Events
  Denominator: Days on Study
  Model: Normal Approximation
  Score: Adjusted Z-Score
  vThreshold: 
    - -2
    - -1
    - 2
    - 3
  nMinDenominator: 30
steps:
  - name: Input_Rate
    output: dfInput
    params:
      dfSubjects: dfEnrolled
      dfNumerator: dfAE
      dfDenominator: dfEnrolled
      strSubjectCol: subjid
      strGroupCol: siteid
      strNumeratorMethod: Count
      strDenominatorMethod: Sum
      strDenominatorCol: timeonstudy
  - name: Transform_Rate
    output: dfTransformed
    params:
      dfInput: dfInput
  - name: Analyze_NormalApprox
    output: dfAnalyzed
    params:
      dfTransformed: dfTransformed
      strType: rate
  - name: Analyze_NormalApprox_PredictBounds
    output: dfBounds
    params:
      dfTransformed: dfTransformed
      vThreshold: vThreshold
      strType: rate
  - name: Flag_NormalApprox
    output: dfFlagged
    params:
      dfAnalyzed: dfAnalyzed
      vThreshold: vThreshold
  - name: Summarize
    output: dfSummary
    params: 
      dfFlagged: dfFlagged
      nMinDenominator: nMinDenominator
```
