---
title: "Qualification Report for the {gsm} R Package"
date: "Report Run Date: `r Sys.Date()`"
subtitle: "`r paste0('{gsm} v', packageVersion('gsm'))`"
output: 
  pdf_document:
    toc: true
    number_sections: true
    extra_dependencies: ["float"]
header-includes:
  - \usepackage{longtable}
vignette: >
  %\VignetteIndexEntry{Qualification}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown_notangle}
---

```{r setup, echo=FALSE, warning=FALSE}
suppressPackageStartupMessages({
  library(gsm)
  library(gt)
  library(knitr)
  library(dplyr)
  library(purrr)
  library(pander)
  library(gh)
  library(stringr)
  library(riskmetric)
  suppressMessages(devtools::load_all())
})

opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE,
  echo = FALSE,
  results = "asis",
  message = FALSE,
  tidy = FALSE,
  fig.pos = "H",
  out.extra = ""
)

source(here::here("inst", "qualification", "specs.R"))
source(here::here("inst", "qualification", "test_cases.R"))
spec_df <- import_specs()
```

\newpage

# Introduction

Risk-Based Quality Monitoring (RBQM) is a proactive approach to clinical trial monitoring that focuses on identifying and addressing the most critical risks to the integrity of study data and patient safety. This approach aims to ensure that study data are accurate, reliable, and credible while optimizing the use of resources and minimizing the burden on study sites.

The `{gsm}` R package supports RBQM by performing risk assessments primarily focused on detecting differences in quality at the site level. This approach is intended to detect potential issues related to critical data or process(es) across the major risk categories of safety, efficacy, disposition, treatment, and general quality. Each category consists of one or more risk assessment(s). Each risk assessment analyzes the data to flag sites with potential outliers and provides a visualization to help the user understand the issue.

# Scope

Qualification testing ensures that core functions execute as expected on a system-wide scale. Qualification includes executing various functional, performance, and usability testing. Qualification tests are designed to provide developers with a repeatable process that is easy to update and document. This document summarizes the qualification testing performed on `{gsm}` functions essential to the analysis workflow.

# Process Overview

Each essential `{gsm}` workflow function is independently qualified using specifications and test cases compiled in this report. Details are provided below.

## Specifications

Specifications capture the most critical use cases for a given function. Each function must have at least one (1) specification, and each specification must have at least one (1) associated test case. Multiple specifications may exist for a function, and multiple test cases may exist for a specification.

Each specification includes the following components:

-   **Description:** outlines the use case for the specification

-   **Risk Assessment**

    -   **Risk Level:** assigned a value of "Low", "Medium", or "High", corresponding to the risk associated with the specification failing

    -   **Risk Impact:** assigned a value of "Low", "Medium", or "High", corresponding to the severity of the impact associated with the specification failing

-   **Test Cases:** lists measurable test cases associated with the specification

## Test Cases

Test cases translate specifications into testable scripts to confirm that the package functions meet the established requirements. Test cases represent how a user may utilize the function to help identify code gaps and support testing automation.

Test cases for `{gsm}` are written using the standard `testthat` workflow. A single test script is saved for each test case and is named following the convention `test_qual_{TestID}.R`, where `TestID` is the test case number. Test code within these scripts is written clearly and concisely to facilitate quick execution and interpretability. Note that a single test case may be associated with multiple specifications.

# Test Results: Overview

```{r results = "hide"}
spec_list <- list.files(here::here('tests', 'testqualification', 'qualification'), pattern = "test-qual_", full.names = TRUE)

scrape <- map_df(spec_list, function(x) {
    testResultsRaw <- testthat::test_file(x, reporter = testthat::ListReporter, package = "gsm") %>% 
      as_tibble()
    
    return(testResultsRaw)
}) %>% 
  mutate(Tests = gsub("test-qual_", "", file),
         Tests = gsub(".R", "", Tests))

funcs <- spec_df %>%
  select(Tests, Assessment) %>%
  tidyr::separate_rows("Tests", sep = ",") %>%
  mutate(Tests = trimws(Tests)) %>%
  rename(Function = Assessment) %>%
  distinct()

testResultsIndividual <- left_join(scrape, funcs, by = "Tests") %>% 
  group_by(Function) %>%
  reframe(`Function Name` = unique(Function),
          `Number of Tests` = sum(nb),
          `Number Passed` = sum(passed),
          `Number Failed` = sum(failed),
          `Number Skipped` = sum(skipped)) %>%
  arrange(`Function Name`) %>%
  select(-Function)

scrape_new <- left_join(scrape, funcs, by = "Tests") 
```

```{r}
testResultsIndividual %>%
  gt() %>%
  tab_options(
    table.font.size = px(9),
    table.width = pct(80)  # Adjust width as needed
  ) %>% 
  opt_row_striping() 
```

# Test Results: Detailed

## One Row Per Specification

```{r}
qual_specs_orig <- read.csv(system.file("qualification", "qualification_specs.csv", package = "gsm"))
qual_specs <- qual_specs_orig %>%
  mutate(SpecID = paste0("S", Spec, "_", Test.ID)) %>%
  select(Specs = SpecID, Tests, N.Tests)

### One row per spec
Specifications <- spec_df %>%
  select(ID, Description, Risk, Impact, Tests) %>%
  mutate(sort1 = as.numeric(str_extract(ID, "(?<=S)\\d+")),
         sort2 = as.numeric(str_extract(ID, "\\d+$"))) %>%
  arrange(as.numeric(sort1), as.numeric(sort2)) %>%
  select(-c(sort1, sort2))
colnames(Specifications) <- c("Spec ID", "Spec Description", "Risk", "Impact", "Associated Test IDs")

Specifications %>%
  gt() %>%
  tab_options(
    table.font.size = px(9)
  )%>%
  cols_width(
    `Spec Description` ~ px(180), 
    `Associated Test IDs` ~ px(150) 
  ) %>%
  opt_row_striping() 
```

\newpage

## One Row Per Test

```{r}
### One row per test
test <- scrape_new %>%
  mutate(result_new = ifelse(failed == 0, "Pass", "Fail")) %>%
  select(Tests, test, result_new, Function)

Results <- left_join(test, qual_specs, by = "Tests") %>%
  select(Function, Specs, Tests, test, result_new) %>%
  mutate(sort1 = as.numeric(str_extract(Tests, "(?<=T)\\d+")),
         sort2 = as.numeric(str_extract(Tests, "\\d+$"))) %>%
  arrange(as.numeric(sort1), as.numeric(sort2)) %>%
  select(-c(sort1, sort2))
colnames(Results) <- c("Function", "Spec ID", "Test ID", "Test Description", "Test Result")

Results %>%
  gt() %>%
  tab_options(
    table.font.size = px(9)
  ) %>%
  cols_width(
    `Function` ~ px(120), 
    `Spec ID` ~ px(90),
    `Test Description` ~ px(180)
  ) %>%
  opt_row_striping() 
```

\newpage

# Unit Tests

## Unit Testing Overview

Unit testing was performed in addition to qualification testing to help ensure that individual pieces of code within the R package function correctly and produce the expected results. By testing individual units of code in isolation, developers can identify and fix issues early in the development process before more significant and scaled problems arise.

## Unit Test Coverage

The table below summarizes unit test coverage of each `{gsm}` function. This metric quantifies the extent of unit testing. The closer this measure is to 100%, the more unit testing that function has.

```{r covr}
pkg_cov <- covr::coverage_to_list(covr::package_coverage(here::here()))

pkg_cov_df <- as.data.frame(pkg_cov)
pkg_cov_df <- tibble::rownames_to_column(pkg_cov_df, "Function")

add1 <- pkg_cov_df[1,]
add1$Function <- "Total Coverage"
add1$filecoverage <- add1$totalcoverage
add1$totalcoverage <- NULL

pkg_coverage <- pkg_cov_df %>%
  select(-totalcoverage) %>%
  rbind(add1) %>%
  mutate(filecoverage = sprintf("%.2f", round(filecoverage, 5)),
         filecoverage = paste(filecoverage, "%")) %>%
  rename(`File Coverage` = filecoverage)

pkg_coverage %>%
  gt() %>%
  tab_options(
    table.font.size = px(9)
  ) %>%
  opt_row_striping() 
```

\newpage

# Qualification Testing Environment

## Session Information

```{r sessioninfo}
pander::pander(sessionInfo())
pander::pandoc.p('\\pagebreak')
```

\newpage

## Package List

The table below utilizes the `riskmetric` package, which quantifies the robustness of an R package. The `pkg_score` column captures the risk involved with using a package. The risk level ranges from 0 (low risk) to 1 (high risk).

<!-- The `downloads` column captures a corrected measure of the volume of downloads by users in the last year. The more times a package has been downloaded, the more extensive the user testing and the greater the chance of identifying and logging a bug. When interpreting `downloads`, the scale goes from 0 to 1. The closer `downloads` is to 1, the better the package score is considered. -->

```{r riskmetric, warning = FALSE}
import_risk <- strsplit(devtools::as.package(here::here())$imports, ",\n")[[1]] %>%
  map_chr(~gsub( " .*$", "", .x )) %>%
  pkg_ref() %>%
  pkg_assess() %>%
  pkg_score() %>%
  select("package", "version", "pkg_score") %>%
  mutate(pkg_score = sprintf("%.3f", round(pkg_score, 5)))

import_risk %>%
  gt() %>%
  tab_options(
    table.font.size = px(9)
  ) %>%
  opt_row_striping() 
```

\newpage

# Pull Request History

```{r prs}
release <- gh("/repos/Gilead-BioStats/gsm/releases", .token = remotes:::github_pat())[[1]]
release_date <- ifelse(is.null(release$published_at), release$created_at, release$published_at)

pr_at_date <- FALSE
page_num <- 1
prs <- list()
while(pr_at_date != TRUE){
  resp <- gh("/repos/Gilead-BioStats/gsm/pulls", per_page = 100, .token = remotes:::github_pat(),
             .params = list(page = page_num, state = "all"))

  map(resp, function(x){
    if (!is.null(x$closed_at) &
        min(as.character(x$closed_at), as.POSIXct(Sys.time())) < as.character(release_date)){
      pr_at_date <<- TRUE
      }
    })

  if (pr_at_date == TRUE){
    resp_sub <- resp %>%
      keep(~ !is.null(.$closed_at) &
             min(as.character(.$closed_at), as.POSIXct(Sys.time())) < as.character(release_date))
    prs <<- append(prs, resp_sub)

  }else{
    prs <<- append(prs, resp)
  }
  page_num <<- page_num + 1
}

getRepoDetails <- function(x) {

  PullRequest <- x[["number"]]
  Requester <- x[["user"]][["login"]]
  DateRequested <- x[["created_at"]]
  Branch <- x[["head"]][["ref"]]
  Target <- x[["base"]][["ref"]]
  Title <- x[["title"]]
  Link <- x[["html_url"]]

  if (length(x[["requested_reviewers"]]) > 0) {
    Reviewers <- paste(map(x[["requested_reviewers"]], ~ .x[["login"]]), collapse = "\n\n")
  } else {
    Reviewers = ""
  }

  tempReviews <- gh(paste0("GET /repos/Gilead-BioStats/gsm/pulls/", PullRequest, "/reviews"))

  if (length(tempReviews) > 0) {
  ReviewStatus <- tempReviews[[1]][["state"]]
  ReviewComments <- tempReviews[[1]][["body"]]
  } else {
    ReviewStatus <- ""
    ReviewComments <- "None"
  }

  pr <- tibble(
    `Pull Request` = PullRequest,
    Requester = Requester,
    `Date Requested` = gsub("T|Z", " ", DateRequested),
    Branch = Branch,
    Target = Target,
    Title = Title,
    Reviewers = Reviewers,
    `Review Status` = ReviewStatus,
    Link = Link
  ) %>%
    map(~ gsub("[^\u0001-\u007F]+|<U\\+\\w+>","", .x)) %>%
    map(~ gsub("`", " ` ", .x)) %>%
    map(~ str_squish(.x)) %>%
    map(~ trimws(.x))

  return(pr)

}

tbl <- map_df(prs, ~getRepoDetails(.))

for (i in 1:nrow(tbl)){
  pander::pandoc.p(
    c(
      pander::pandoc.header(paste0("Pull Request ", tbl[i, "Pull Request"], ": ", tbl[i, "Title"]), level = 3),
      pander::pandoc.p(paste0("Merging ", tbl[i, "Branch"], " into ", tbl[i, "Target"], "\n")),
      pander::pandoc.p(pander::pandoc.link(tbl[i, "Link"])),
      pander::pandoc.table(tbl[i, c("Requester", "Date Requested",
                                    "Reviewers", "Review Status")],
                           split.cells = 13)
      )
    )
}
```
