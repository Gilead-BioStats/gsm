---
title: "Cookbook"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Cookbook}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(gsm)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

This vignette contains a series of examples showing how to run analysis workflows for the Good Statistical Monitoring `{gsm}` package using sample data from [`{clindata}`](https://github.com/Gilead-BioStats/clindata). 

`{gsm}` leverages Key Risk Indicators (KRIs) and thresholds to conduct study-level and site-level Risk Based Monitoring for clinical trials.

For more information on the `{gsm}` package see the [package homepage](https://gilead-biostats.github.io/gsm/). The [Data Pipeline Vignette](https://gilead-biostats.github.io/gsm/articles/DataPipeline.html) provides additional technical details including data specifications and handling of metadata. The [Data Analysis Vignette](https://gilead-biostats.github.io/gsm/articles/DataAnalysis.html) provides detailed information about the nested functions that support the analysis workflows.

## Setup and Installation

### Install `{gsm}`, `{clindata}`, and `{safetyData}`

Run the following:

```{r eval = FALSE, include = TRUE}
## Install devtools
install.packages('devtools')

## Install and load sample raw data
devtools::install_github("Gilead-BioStats/clindata", ref = "main")
library(clindata)

## Install and load sample CDISC-compliant SDTM and ADaM data
install.packages('safetyData')
library(safetyData)

## Install and load gsm
devtools::install_github("Gilead-BioStats/gsm", ref = "main")
library(gsm)
```

To use the most recent development version from GitHub, run:

```{r eval = FALSE, include = TRUE}
devtools::install_github("Gilead-BioStats/gsm", ref = "dev")
```

## Data Prep Using Sample Data from `{clindata}`

To run multiple assessments using the sample rawplus data from `{clindata}`, the user can run the following:

It is important to note that `lData` expects a *named* list. To see a list of default data frame names, run `names(gsm::Read_Mapping())`.

```{r eval = FALSE, include = TRUE}
library(gsm)
library(clindata)
library(dplyr)

# Import Site+Study Metadata
dfStudy<-clindata::ctms_study %>% rename(StudyID = protocol_number)
dfSite<- clindata::ctms_site %>% rename(SiteID = site_num)

# Pull Raw Data - this will overwrite the previous data pull
lRaw <- gsm::UseClindata(
  list(
    "dfSUBJ" = "clindata::rawplus_dm",
    "dfAE" = "clindata::rawplus_ae",
    "dfPD" = "clindata::ctms_protdev",
    "dfLB" = "clindata::rawplus_lb",
    "dfSTUDCOMP" = "clindata::rawplus_studcomp",
    "dfSDRGCOMP" = "clindata::rawplus_sdrgcomp %>%
      dplyr::filter(.data$phase == 'Blinded Study Drug Completion')",
    "dfDATACHG" = "clindata::edc_data_points",
    "dfDATAENT" = "clindata::edc_data_pages",
    "dfQUERY" = "clindata::edc_queries",
    "dfENROLL" = "clindata::rawplus_enroll"
  )
)
```

Once the data is loaded into the R session, we can begin running our workflows to produce analytics and reporting outputs.

## Example 1 - Running Assessments on Standard Data with YAML files

All assessments can be run as standalone workflows that create useful data summaries and visualizations. `{gsm}` is configured to accept rawplus data by default, and that data standard is used here. If using YAML files to specify the workflow(s), the process for running one assessment or multiple assessments is identical.

EXPLAIN YAML FILE STRUCTURE

With all necessary data loaded into the session, running assessments is a 2-step process, both using the same `RunWorkflow()` function. The steps are as follows:

1.  Map domain-level data to the input data standard for the assessment(s)
2.  Run the assessment(s) using an appropriate statistical method as specified in the YAML file

First, the `mapping.yaml` workflow is helpful run in order to create the necessary `data.frames` for use in the assessment workflow. This file runs a series of `RunQuery()` calls to create the appropriately filtered and specified data.frames. The full `mapping.yaml` workflow is below, in Appendix A. Here, you will see a subset of the `mapping.yaml` that is relevant to the Important Protocol Deviation Rate workflow.


    meta:
      file: mapping.yaml
      desctipion: Data Mappings to prepare for metric calculations
    steps:
      - name: RunQuery
        output: dfEnrolled
        params:
          df: dfSUBJ
          strQuery: "SELECT subjectid as raw_subjectid, * FROM df WHERE enrollyn == 'Y'"
      - name: RunQuery
        output: dfImportantPD
        params:
          df: dfPD
          strQuery: "SELECT subjectenrollmentnumber as subjid, * FROM df WHERE deemedimportant == 'Yes'"


The second step is to run the assessment workflow.


    meta:
      file: kri0004.yaml
      MetricID: kri0004
      group: site
      abbreviation: PD
      metric: Important Protocol Deviation Rate
      numerator: Important Protocol Deviations
      denominator: Days on Study
      model: Normal Approximation
      score: Adjusted Z-Score
    vThreshold:
      - -3
      - -2
      - 2
      - 3
    steps:
      - name: Input_Rate
        output: dfInput
        params:
          dfSubjects: dfEnrolled
          dfNumerator: dfImportantPD
          dfDenominator: dfEnrolled
          strSubjectCol: subjid
          strGroupCol: siteid
          strNumeratorMethod: Count
          strDenominatorMethod: Sum
          strDenominatorCol: timeonstudy
      - name: Transform_Rate
        output: dfTransformed
        params:
         dfInput: dfInput
      - name: Analyze_NormalApprox
        output: dfAnalyzed
        params:
          dfTransformed: dfTransformed
          strType: rate
      - name: Analyze_NormalApprox_PredictBounds
        output: dfBounds
        params:
          dfTransformed: dfTransformed
          strType: rate
          vThreshold: vThreshold
      - name: Flag_NormalApprox
        output: dfFlagged
        params:
          dfAnalyzed: dfAnalyzed
          vThreshold: vThreshold
      - name: Summarize
        output: dfSummary
        params:
          dfFlagged: dfFlagged


Putting these steps together to run all 12 KRI workflows at once looks like this:

```{r eval = FALSE, include = TRUE}
library(clindata)
library(gsm)

# Prepare Workflows
wf_mapping <- MakeWorkflowList(strNames="mapping")
wf_metrics <- MakeWorkflowList(strNames=paste0("kri",sprintf("%04d", 1:12)))

# Create Mapped Data
lMapped <- RunWorkflow(lWorkflow = wf_mapping, 
                       lData = lRaw)
# Run KRI workflows
lResults <- RunWorkflow(lWorkflow = wf_metrics, 
                        lData = lMapped$mapping$lResults)
```

Each assessment has representative examples in the help files. The example above can be reviewed by entering `?AE_Assess` into the console.

## Example 2 - Running a Single Assessment Step-by-Step Using Standard Data

Let's look at an illustrative example of everything that happens behind the scenes when running an individual `Assess()` function. It may be helpful to reference this example alongside the [Data Analysis Vignette](https://gilead-biostats.github.io/gsm/articles/DataAnalysis.html), which goes into significantly more detail about each nested function involved in this workflow. The image below is a high-level summary:

![](data-analysis.PNG)

As displayed in the YAML files of Example 1, we will use the PD workflow (KRI0004) for this example.

```{r eval = FALSE, include = TRUE}
library(clindata)
library(gsm)

# Prepare Workflow
wf_mapping <- MakeWorkflowList(strNames="mapping")

# Create Mapped Data
lMapped <- RunWorkflow(lWorkflow = wf_mapping, 
                       lData = lRaw)
```

Start by creating `dfInput` using sample rawplus data from `{clindata}`. Note that `Input_Rate()` requires three specific datasets from `{clindata}`, which include a subject-level demographics/exposure dataset (`dfSubjects`) and a domain-level dataset (`dfNumerator`) that records every adverse event per subject. 

Since `Input_Rate()` is a generalized function, it is also required that you specify the relevant column names for the Subject (`strSubjectCol`), Group (`strGroupCol`) and optionally the Denominator (`strDenominatorCol`) and Numerator (`strNumeratorCol`) when it is not simply "Denominator" or "Numerator", respectively.

Finally, the method for calculating the Numerator and Denominator is specified in `strNumeratorMethod` and `strDenominatorMethod` as either "Count" or "Sum".  If the method is "Count", the function simply counts the number of rows in the provided data frame. If the numerator method is "Sum", the function takes the sum of the values in the specified column (strNumeratorCol or strDenominatorCol). The function returns a data frame with the calculated input rate for each subject.

```{r eval = FALSE, include = TRUE}
dfInput <- Input_Rate(
              dfSubjects =  lMapped$mapping$lResults$dfEnrolled
              dfNumerator = lMapped$mapping$lResults$dfImportantPD
              dfDenominator = lMapped$mapping$lResults$dfEnrolled
              strSubjectCol = "subjid"
              strGroupCol = "siteid"
              strNumeratorMethod = "Count"
              strDenominatorMethod = "Sum"
              strDenominatorCol = "timeonstudy"
)
```

The second step is to transform `dfInput` into site-level summary data, which is needed to derive the KRI. Two `Transform()` functions are available, `Transform_Rate()` and `Transform_Count()`, and `Transform_Rate()` is the function that is used with the PD assessment. Note that `strNumeratorCol`and `strDenominatorCol` are optional, with the default values being "Numerator" and "Denominator".

```{r eval = FALSE, include = TRUE}
dfTransformed <- Transform_Rate(
  dfInput
  )
```

The third step is to analyze the transformed data. Certain assessments support multiple statistical models/`Analyze()` functions, so the user needs to specify certain parameters for the intended analysis to run. We use the normal approximation method in this example (the default method for all standard KRIs).

```{r eval = FALSE, include = TRUE}
dfAnalyzed <- Analyze_NormalApprox(dfTransformed)
```

After analyzing the transformed data, we will flag sites based on at least one statistical threshold. Similar to the previous step, multiple flag functions exist to support the assessment functions. The `Flag_NormalApprox()` function is one of several options for the PD assessment. 

- If a site falls outside of the (-2, 2) range, it is considered to be "Amber" and will be assigned a value of -1 or 1. 
- If a site falls outside of the (-3, 3) range, it is considered "Red" and will be assigned a value of -2 or 2. 

Both are considered to be outliers, but "Red" sites are more extreme outliers.

```{r eval = FALSE, include = TRUE}
dfFlagged <- Flag_NormalApprox(dfAnalyzed, vThreshold = c(-3, -2, 2, 3))
```

Next, we will summarize the flagged data. The `Summarize()` function will only keep the most relevant columns from `dfFlagged` for a given assessment.

```{r eval = FALSE, include = TRUE}
dfSummary <- Summarize(dfFlagged)
```

Finally, we will create a chart that helps to identify/visualize flagged sites. When using the normal approximation method, we can create upper and lower bounds using the `Analyze_NormalApprox_PredictBounds()` function. 

Using the bounds we create and the flagged data frame, we can create a scatter plot. Any sites that are plotted outside of the bounds will be yellow or red. Yellow points indicate "At Risk" sites, and red points indicate "Flagged" sites.

```{r eval = FALSE, include = TRUE}
dfBounds <- Analyze_NormalApprox_PredictBounds(dfTransformed, vThreshold = c(-3, -2, 2, 3))
chart <- Visualize_Scatter(dfFlagged, dfBounds)
```


Reviewing this step-by-step example will allow the user to better understand each intermediate function that runs within a YAML workflow file during KRI derivation. `{gsm}` allows the user to generate the same results in Example 1 and Example 2, with additional error-checking and metadata, and interactive data visualizations. For reference, the code from Example 1 is specified below, only running the PD workflow (KRI0004):

```{r eval = FALSE, include = TRUE}
# Prepare Workflows
wf_mapping <- MakeWorkflowList(strNames = "mapping")
wf_metrics <- MakeWorkflowList(strNames = "kri0004")

# Create Mapped Data
lMapped <- RunWorkflow(lWorkflow = wf_mapping, 
                       lData = lRaw)
# Run KRI workflows
lResults <- RunWorkflow(lWorkflow = wf_metrics, 
                        lData = lMapped$mapping$lResults)
```

# Reporting

## Example 3 - Creating an Assessment Overview Report for Multiple Assessments

### Standard Report via `Study_Assess()`

The `Study_Report()` function creates the **Assessment Overview Report**, which is an HTML document that contains tables, visualizations, and error logging for all assessments run in the `Study_Assess()` workflow.

Let's create a report using sample data from `{clindata}`:

```{r eval = FALSE, include = TRUE}
library(gsm)
library(clindata)

multiple_assessments <- Study_Assess()

Study_Report(lSnapshot = multiple_assessments)
```

The report will render and be saved to your current working directory. If you would like the report saved in a different location, you can set an output directory using the `strOutpath` argument in the `Study_Report()` function.


### Enhanced Report via `Make_Snapshot()`

The `Study_Report()` function also takes on optional arguments (`dfSite` and `dfStudy`) that are used to provide site and study-level reporting. This includes study-level CTMS data displayed in a summary table at the top of the report, and an enhanced **Study Overview** table. 

```{r eval = FALSE, include = TRUE}
library(gsm)
library(clindata)

snapshot <- Make_Snapshot()

Study_Report(
  lSnapshot = snapshot,
  dfSite = snapshot$lSnapshot$status_site, 
  dfStudy = snapshot$lSnapshot$status_study
  )
```

## Example 6 - Viewing the Error Checking Report

The **Assessment Overview Report** contains a Data Check Summary table in the appendix, which can be helpful for troubleshooting issues with input data provided to `lData` in `Study_Assess()`.

To view the report directly as an object in your IDE, run:

```{r eval = FALSE, include = TRUE}
library(gsm)
library(clindata)

multiple_assessments <- Study_Assess()

Study_AssessmentReport(lAssessments = multiple_assessments, bViewReport = TRUE)
```

# Visualizations

By default, all `Assess()` functions return a visualization whether run individually or within the `Study_Assess()` workflow. For example, the scatter plot for the AE assessment can be viewed by calling `AE_Assess(dfInput)$lCharts$scatter`.

## Example 7 - Creating a Scatter Plot

`{gsm}` creates static and interactive charts using `{ggplot2}` and a custom JavaScript charting library `{rbm-viz}`. 

Customizing interactive JavaScript widgets will be covered in a separate vignette.

Below is an example of creating a static `{ggplot2}` scatter plot that uses the default normal approximation method for `AE_Assess()` and rawplus data from `{clindata}`:

```{r eval = FALSE, include = TRUE}
library(gsm)
library(clindata)

## Map domain-level data to the input data standard for the selected assessment
dfInput <- AE_Map_Raw()

## Run the assessment
ae_assessment <- AE_Assess(dfInput)

## Create threshold boundaries 
dfBounds <- Analyze_NormalApprox_PredictBounds(
  dfTransformed = ae_assessment$lData$dfTransformed,
  vThreshold = c(-3, -2, 2, 3)
  )

## Create the visualization
Visualize_Scatter(
  dfSummary = ae_assessment$lData$dfFlagged, 
  dfBounds = dfBounds
  )
```

# Custom Mapping/YAML Specifications

As mentioned in Appendix 1 of the [Data Pipeline Vignette](https://gilead-biostats.github.io/gsm/articles/DataPipeline.html#Appendix-1-Metadata-Technical-Specifications), `Study_Assess()` triggers a workflow that uses pre-defined YAML specifications that organize all of the required metadata for a given assessment or set of assessments.

In some cases, the user might want to configure their own mappings, which can be done by providing custom YAML mappings for one or more assessments.

Let's take a look at a few examples of editing YAML files for a custom workflow below.

## Example 8 - Adding a Filtering Step

There are filter steps in the default specification for the AE Assessment, but we want to add an additional filter. Let's add a step that filters the `dfAE` data frame so all values of `aetoxgr == "MODERATE"` (i.e., we select for AEs with a moderate toxicity grade):

The default mappings for the AE Assessment are saved under KRI 0001, i.e., `kri0001.yaml`:

    steps:
      - name: FilterDomain
        inputs: dfAE
        output: dfAE
        params:
          strDomain: dfAE
          strColParam: strTreatmentEmergentCol
          strValParam: strTreatmentEmergentVal
      - name: FilterDomain
        inputs: dfAE
        output: dfAE
        params:
          strDomain: dfAE
          strColParam: strSeriousCol
          strValParam: strNonSeriousVal
      - name: AE_Map_Raw
        inputs:
          - dfAE
          - dfSUBJ
        output: dfInput
      - name: AE_Assess
        inputs: dfInput
        output: lResults
        params:
          strGroup: "Site"
          vThreshold: null
          strMethod: "Poisson"

First, we want to add an additional `FilterDomain()` step to the workflow specification to select only moderate AEs. Because `dfAE` needs to be filtered before it is used in `AE_Map_Raw()`, the filter steps need to be placed first in the workflow.

Let's name the custom YAML file `ae_assessment_moderate.yaml`. It reads as follows:

    steps:
      - name: FilterDomain
        inputs: dfAE
        output: dfAE
        params:
          strDomain: dfAE
          strColParam: strTreatmentEmergentCol
          strValParam: strTreatmentEmergentVal
      - name: FilterDomain
        inputs: dfAE
        output: dfAE
        params:
          strDomain: dfAE
          strColParam: strSeriousCol
          strValParam: strNonSeriousVal
      - name: FilterDomain
        inputs: dfAE
        output: dfAE
        params:
          strDomain: dfAE
          strColParam: strModerateCol
          strValParam: strModerateVal
      - name: AE_Map_Raw
        inputs:
          - dfAE
          - dfSUBJ
        output: dfInput
      - name: AE_Assess
        inputs: dfInput
        output: lResults
        params:
          strGroup: "Site"
          vThreshold: null
          strMethod: "Poisson"

After setting up the custom YAML mapping, there are a few more steps a user must take before executing `Study_Assess()`:

1.  Read in the default workflow mapping from `gsm::MakeWorkflowList()`.
2.  Overwrite `lAssessmentsCustom$kri0001` with the custom YAML file (`ae_assessment_moderate.yaml`).
3.  Add a name value to the custom assessment list.
4.  Add a relative path to the custom assessment list, to show where the custom YAML file is stored.
5.  Read in the default rawplus mappings from `{clindata}`.
6.  Add the value to sort `strTypeCol` on.
7.  Run the `Study_Assess()` workflow.

```{r eval = FALSE, include = TRUE}
library(gsm)
library(clindata)
library(yaml)

## 1. Read in default workflow mapping
lAssessmentsCustom <- MakeWorkflowList()

## 2. Apply custom AE assessment mapping
lAssessmentsCustom$kri0001 <- yaml::read_yaml("ae_assessment_moderate.yaml")

## 3. Add a name value, i.e., the variable you want to filter on
lAssessmentsCustom$kri0001$name <- "aetoxgr"

## 4. Add the location of the custom YAML file
lAssessmentsCustom$kri0001$path <- getwd()

## 5. Read in default data set mappings from `{clindata}`
lMappingCustom <- gsm::Read_Mapping()

## 6. Add strTypeVal, i.e., the value for strTypeCol to filter on
lMappingCustom$dfAE$strGradeCol <- "MODERATE"

## 7. Run the Study_Assess workflow
customStudy <- Study_Assess(lMapping = lMappingCustom, lAssessments = lAssessmentsCustom)
```
